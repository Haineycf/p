{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://www.analyticsvidhya.com/wp-content/uploads/2016/08/MLalgorithms-.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_variables_values_training_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6298301d5e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#Identify feature and response variable(s) and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;31m#values must be numeric and numpy arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_variables_values_training_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_variables_values_training_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_variables_values_test_datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_variables_values_training_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "#Import other necessary libraries like pandas,\n",
    "#numpy...\n",
    "from sklearn import linear_model\n",
    "#Load Train and Test datasets\n",
    "#Identify feature and response variable(s) and\n",
    "#values must be numeric and numpy arrays\n",
    "x_train=input_variables_values_training_datasets\n",
    "y_train=target_variables_values_training_datasets\n",
    "x_test=input_variables_values_test_datasets\n",
    "#Create linear regression object\n",
    "linear = linear_model.LinearRegression()\n",
    "#Train the model using the training sets and\n",
    "#check score\n",
    "linear.fit(x_train, y_train)\n",
    "linear.score(x_train, y_train)\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', linear.coef_)\n",
    "print('Intercept: \\n', linear.intercept_)\n",
    "#Predict Output\n",
    "predicted= linear.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5b781b7cbbd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m#Train the model using the training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m#and check score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;31m#Equation coefficient and Intercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Assumed you have, X (predictor) and Y (target)\n",
    "#for training data set and x_test(predictor)\n",
    "#of test_dataset\n",
    "#Create logistic regression object\n",
    "model = LogisticRegression()\n",
    "#Train the model using the training sets\n",
    "#and check score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "#Equation coefficient and Intercept\n",
    "print('Coefficient: \\n', model.coef_)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "#Import other necessary libraries like pandas, numpy...\n",
    "from sklearn import tree\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of\n",
    "#test_dataset\n",
    "#Create tree object\n",
    "model = tree.DecisionTreeClassifier(criterion='gini')\n",
    "#for classification, here you can change the\n",
    "#algorithm as gini or entropy (information gain) by\n",
    "#default it is gini\n",
    "#model = tree.DecisionTreeRegressor() for\n",
    "#regression\n",
    "#Train the model using the training sets and check\n",
    "#score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import svm\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of test_dataset\n",
    "#Create SVM classification object\n",
    "model = svm.svc()\n",
    "#there are various options associated\n",
    "with it, this is simple for classification.\n",
    "#Train the model using the training sets and check\n",
    "#score\n",
    "model.fit(X, y)\n",
    "model.score(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of test_dataset\n",
    "#Create SVM classification object model = GaussianNB()\n",
    "#there is other distribution for multinomial classes\n",
    "like Bernoulli Naive Bayes\n",
    "#Train the model using the training sets and check\n",
    "#score\n",
    "model.fit(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of test_dataset\n",
    "#Create KNeighbors classifier object model\n",
    "KNeighborsClassifier(n_neighbors=6)\n",
    "#default value for n_neighbors is 5\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.cluster import KMeans\n",
    "#Assumed you have, X (attributes) for training data set\n",
    "#and x_test(attributes) of test_dataset\n",
    "#Create KNeighbors classifier object model\n",
    "k_means = KMeans(n_clusters=3, random_state=0)\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of test_dataset\n",
    "#Create Random Forest object\n",
    "model= RandomForestClassifier()\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import decomposition\n",
    "#Assumed you have training and test data set as train and\n",
    "#test\n",
    "#Create PCA object pca= decomposition.PCA(n_components=k)\n",
    "#default value of k =min(n_sample, n_features)\n",
    "#For Factor analysis\n",
    "#fa= decomposition.FactorAnalysis()\n",
    "#Reduced the dimension of training dataset using PCA\n",
    "train_reduced = pca.fit_transform(train)\n",
    "#Reduced the dimension of test dataset\n",
    "test_reduced = pca.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting and Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for\n",
    "#training data set and x_test(predictor) of test_dataset\n",
    "#Create Gradient Boosting Classifier object\n",
    "model= GradientBoostingClassifier(n_estimators=100, \\\n",
    " learning_rate=1.0, max_depth=1, random_state=0)\n",
    "#Train the model using the training sets and check score\n",
    "model.fit(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
